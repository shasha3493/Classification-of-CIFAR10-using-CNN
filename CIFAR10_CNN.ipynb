{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg6dn83ykpSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.optim as optim\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFqV_S6R9K54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWvieGvklxe4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrPmTK43lV8-",
        "colab_type": "code",
        "outputId": "0a2a064b-4668-4e18-ce2e-a58a9b55b1ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_data = datasets.CIFAR10('data',train = True, transform=transform,  download=True)\n",
        "test_data = datasets.CIFAR10('data',train = False, transform=transform, download=True )\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bwnvHpUnFfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 20\n",
        "\n",
        "train_size = len(train_data)\n",
        "# print(train_size)\n",
        "valid_size = 0.2\n",
        "\n",
        "indices = list(range(train_size))\n",
        "valid_size = int(np.floor(0.2*train_size))\n",
        "# print(valid_size)\n",
        "\n",
        "train_idx = indices[valid_size:]\n",
        "valid_idx = indices[:valid_size]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data,sampler = train_sampler, batch_size=batch,shuffle = False)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data,sampler = valid_sampler, batch_size=batch,shuffle = False)\n",
        "test_loader =  torch.utils.data.DataLoader(test_data, batch_size=batch,shuffle = True)\n",
        "\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-vNXuRGuZ2S",
        "colab_type": "code",
        "outputId": "3a2282e6-e0e1-4dee-b6e4-c00f95cecd0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "for data, labels in train_loader:\n",
        "  print(data.shape)\n",
        "  print(labels)\n",
        "  break\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([20, 3, 32, 32])\n",
            "tensor([7, 6, 9, 5, 6, 9, 9, 0, 2, 3, 6, 8, 2, 4, 3, 4, 6, 8, 8, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAojurc1uf6u",
        "colab_type": "code",
        "outputId": "d6152a63-498d-486f-ab87-e00f3a7184ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "class CNN(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(CNN,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3,32,(3,3),1,1)\n",
        "    self.conv2 = nn.Conv2d(32,64,(3,3),1,1)\n",
        "    self.conv3 = nn.Conv2d(64,128,(3,3),1,1)\n",
        "    self.conv4 = nn.Conv2d(128,64,(3,3),1,1) \n",
        "\n",
        "    self.fc1 = nn.Linear(256,128)\n",
        "    self.fc2 = nn.Linear(128,64)\n",
        "    self.fc3 = nn.Linear(64,10)\n",
        "\n",
        "    self.maxpool = nn.MaxPool2d((2,2))\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=F.relu(self.conv1(x))\n",
        "    x=self.maxpool(x)\n",
        "    # print(x.shape)\n",
        "    x=F.relu(self.conv2(x))\n",
        "    x=self.maxpool(x)\n",
        "    # print(x.shape)\n",
        "    x=F.relu(self.conv3(x))\n",
        "    x=self.maxpool(x)\n",
        "    # print(x.shape)\n",
        "    x=F.relu(self.conv4(x))\n",
        "    x=self.maxpool(x)\n",
        "    # print(x.shape)\n",
        "    x=x.view(-1,x.shape[1]*x.shape[2]*x.shape[3])\n",
        "    # print(x.shape)\n",
        "    x=F.relu(self.fc1(x))\n",
        "    x=F.relu(self.fc2(x))\n",
        "    x=self.fc3(x)\n",
        "    return(x)\n",
        "\n",
        "\n",
        "cnn = CNN()\n",
        "cnn.to(device)\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da6cD-8V1nuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(cnn.parameters(), lr=0.01,momentum=0.9)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe3B9LOO6fCg",
        "colab_type": "code",
        "outputId": "e8e486df-2ba6-45df-b3e0-5286b12f0447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epoch = 30\n",
        "min_val_loss=np.Inf\n",
        "for i in range(epoch):\n",
        "  correct_pred = 0\n",
        "  correct_pred_v=0\n",
        "  running_loss_v=0\n",
        "  running_loss=0\n",
        "  \n",
        "  \n",
        "  for data,label in train_loader:\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    # print(data.shape)\n",
        "    p = cnn.forward(data.to(device))\n",
        "    prob = F.softmax(p,1)\n",
        "    # print(prob)\n",
        "    _,pred_class = torch.max(prob,1)\n",
        "    correct_pred += torch.sum(pred_class == label.to(device)).item()\n",
        "    # print(correct_pred)  \n",
        "    loss=criterion(p,label.to(device))\n",
        "    # print(data.shape[0])\n",
        "    loss.backward()\n",
        "    running_loss+=loss.item()*data.shape[0]\n",
        "    optimizer.step()\n",
        "  \n",
        "  # Validation:\n",
        "\n",
        "  for data_v,label_v in valid_loader:\n",
        "    data_v, label_v = data_v.to(device), label_v.to(device)\n",
        "    p_v = cnn.forward(data_v)\n",
        "    prob_v = F.softmax(p_v,1)\n",
        "    _,pred_class_v = torch.max(prob_v,1)\n",
        "    correct_pred_v += torch.sum(pred_class_v == label_v).item()\n",
        "    # print(correct_pred_v)\n",
        "    loss_v=criterion(p_v,label_v)\n",
        "    running_loss_v+=loss_v.item()*data_v.shape[0]\n",
        "\n",
        "  print(\"Training Dataset: \")    \n",
        "  print(\"Epoch: {}  Loss: {}  Accuracy: {}\".format(i,running_loss/len(train_loader.sampler),correct_pred/len(train_loader.sampler)))\n",
        "  print()\n",
        "  print('*'*50)\n",
        "  print()\n",
        "  print('Validation: ')\n",
        "  print('Loss: {}  Accuracy: {}'.format(running_loss_v/len(valid_loader.sampler),correct_pred_v/len(valid_loader.sampler)))\n",
        "  print()\n",
        "  if (running_loss_v/len(valid_loader.sampler) < min_val_loss):\n",
        "    print('Saving the model')\n",
        "    torch.save(cnn.state_dict(),'checkpoint.pt')\n",
        "    min_val_loss = running_loss_v/len(valid_loader.sampler)\n",
        "    print('New minimum validation loss:',min_val_loss)\n",
        "  print()\n",
        "  print()\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Dataset: \n",
            "Epoch: 0  Loss: 1.8192537057697773  Accuracy: 0.31315\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 1.5205116658210753  Accuracy: 0.454\n",
            "\n",
            "Saving the model\n",
            "New minimum validation loss: 1.5205116658210753\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 1  Loss: 1.2478242857456208  Accuracy: 0.54495\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 1.1044011603593826  Accuracy: 0.6034\n",
            "\n",
            "Saving the model\n",
            "New minimum validation loss: 1.1044011603593826\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 2  Loss: 1.0006090006232262  Accuracy: 0.6477\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 0.89627119743824  Accuracy: 0.6866\n",
            "\n",
            "Saving the model\n",
            "New minimum validation loss: 0.89627119743824\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 3  Loss: 0.868380557090044  Accuracy: 0.6952\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 0.8462098114490509  Accuracy: 0.7045\n",
            "\n",
            "Saving the model\n",
            "New minimum validation loss: 0.8462098114490509\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 4  Loss: 0.768410406678915  Accuracy: 0.73385\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 0.8806848283708095  Accuracy: 0.7018\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 5  Loss: 0.6901435976326465  Accuracy: 0.7616\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 0.8249719802737236  Accuracy: 0.7246\n",
            "\n",
            "Saving the model\n",
            "New minimum validation loss: 0.8249719802737236\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 6  Loss: 0.641213359259069  Accuracy: 0.779875\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 0.8503674407601356  Accuracy: 0.7208\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 7  Loss: 0.6008560660369694  Accuracy: 0.791575\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 0.7952117540538312  Accuracy: 0.734\n",
            "\n",
            "Saving the model\n",
            "New minimum validation loss: 0.7952117540538312\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 8  Loss: 0.5677151111001149  Accuracy: 0.806125\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 0.8507461015582085  Accuracy: 0.7253\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 9  Loss: 0.5336891726404428  Accuracy: 0.815525\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 0.9020190353095532  Accuracy: 0.722\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 10  Loss: 0.5067683652769774  Accuracy: 0.82985\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 0.9313808423876763  Accuracy: 0.7142\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 11  Loss: 0.5097754635149613  Accuracy: 0.826975\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 0.9768716306686401  Accuracy: 0.7141\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 12  Loss: 0.4991754519129172  Accuracy: 0.8324\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 0.9328765801787376  Accuracy: 0.7252\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 13  Loss: 0.5073019054243341  Accuracy: 0.830975\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 1.039295415326953  Accuracy: 0.7199\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 14  Loss: 0.5029704510951415  Accuracy: 0.83795\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 1.094455852329731  Accuracy: 0.6979\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 15  Loss: 0.5169583590077236  Accuracy: 0.83335\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 1.060723220437765  Accuracy: 0.7031\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 16  Loss: 0.5364224858866073  Accuracy: 0.82745\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 1.1331824632287026  Accuracy: 0.6973\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 17  Loss: 0.5227344436002895  Accuracy: 0.83425\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 0.9932597565352916  Accuracy: 0.711\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 18  Loss: 0.5777095011593774  Accuracy: 0.822375\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 1.1151191497147084  Accuracy: 0.6917\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 19  Loss: 0.6266696228310465  Accuracy: 0.80845\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 1.152534952968359  Accuracy: 0.7114\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 20  Loss: 0.6329883822724223  Accuracy: 0.808625\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 1.104883098423481  Accuracy: 0.7052\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 21  Loss: 0.6831793404333294  Accuracy: 0.7956\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 1.310121342778206  Accuracy: 0.6996\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 22  Loss: 0.7443245117552578  Accuracy: 0.7791\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 1.1715235779881477  Accuracy: 0.6786\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 23  Loss: 0.7279871848039329  Accuracy: 0.787525\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 1.2956703649759294  Accuracy: 0.6452\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 24  Loss: 0.8039096750747412  Accuracy: 0.767725\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 1.2898138998150825  Accuracy: 0.6628\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 25  Loss: 0.8206578020807356  Accuracy: 0.761175\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 1.441534837961197  Accuracy: 0.6359\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 26  Loss: 1.22624548894912  Accuracy: 0.603875\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 2.3024220900535584  Accuracy: 0.0955\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 27  Loss: 1.3739611466228963  Accuracy: 0.55745\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 1.663272673010826  Accuracy: 0.5615\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 28  Loss: 1.3053609828799964  Accuracy: 0.603475\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 1.681950236439705  Accuracy: 0.4341\n",
            "\n",
            "\n",
            "\n",
            "Training Dataset: \n",
            "Epoch: 29  Loss: 1.427196826338768  Accuracy: 0.538\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Validation: \n",
            "Loss: 1.4732399084568024  Accuracy: 0.516\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6doTbbz3RK2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "844f1239-a32e-4068-ecec-4ad05b930926"
      },
      "source": [
        "cnn.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "# Testing \n",
        "\n",
        "cnn.eval()\n",
        "with torch.no_grad():\n",
        "  correct_pred = 0\n",
        "  for data,label in test_loader:\n",
        "    data,label = data.to(device),label.to(device)\n",
        "    output = cnn.forward(data)\n",
        "    prob = F.softmax(output,1)\n",
        "    _,pred_class = torch.max(prob,1)\n",
        "    correct_pred += torch.sum(pred_class == label).item()\n",
        "\n",
        "  print('Accuracy on test Data:',correct_pred/len(test_loader.sampler))\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test Data: 0.7305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN4TH_lj3WxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}